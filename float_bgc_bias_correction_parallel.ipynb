{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Float BGC Bias Correction, parallel version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original version: Veronica Tamsitt (USF)\n",
    "\n",
    "Current authors: Seth Bushinsky, Zachary Nachod (UH Manoa)\n",
    "\n",
    "Authors: Veronica Tamsitt (USF) et al...\n",
    "\n",
    "Adapted from MATLAB code written by Seth Bushinsky (UH)\n",
    "\n",
    "    Download and process GLODAP data\n",
    "    apply float bias corrections and calculate derivative variables (pH, TALK)\n",
    "    do float - glodap crossover comparison\n",
    "    do float - float crossover comparison\n",
    "\n",
    "Link to MATLAB LIAR/LIPHR code: https://github.com/BRCScienceProducts/LIRs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob, os\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import functions.float_data_processing as fl\n",
    "import numpy as np\n",
    "import functions.argo_interp_and_crossover as aiac\n",
    "import functions.carbon_utils as carbon_utilities\n",
    "\n",
    "# from gdap_crossover_intermediate_script import process_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a user-created text file to point to local directories to avoid having to change this every time \n",
    "# we update code\n",
    "lines=[]\n",
    "with open('path_file.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "count = 0\n",
    "for line in lines:\n",
    "    count += 1\n",
    "    index = line.find(\"=\")\n",
    "    #print(f'line {count}: {line}')\n",
    "    #print(index)\n",
    "    #print(line[0:index])\n",
    "    line = line.rstrip()\n",
    "    if line[0:index].find(\"argo\")>=0:\n",
    "        argo_path=line[index+1:]\n",
    "    elif line[0:index].find(\"liar\")>=0:\n",
    "        liar_dir=line[index+1:]\n",
    "    elif line[0:index].find(\"matlab\")>=0:\n",
    "        matlab_dir=line[index+1:]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User definted inputs\n",
    "\n",
    "adjustment = True # allows to read in outputs from previous crossover and apply them in a rough approximation of correction \n",
    "\n",
    "#pressure limits for interpolation of \n",
    "p_interp_min = 1450 #minimum pressure for float crossover comparison\n",
    "p_interp_max = 2000 #maximum pressure for float crossover comparison\n",
    "# p_interp_min = 1 #minimum pressure for float crossover comparison\n",
    "# p_interp_max = 500 #maximum pressure for float crossover comparison\n",
    "#pressure levels to interpolate to, every 1db\n",
    "p_interp = np.arange(p_interp_min,p_interp_max+1)\n",
    "\n",
    "# select glodap pressure range for comparison\n",
    "p_compare_min = 1400\n",
    "p_compare_max = 2100\n",
    "\n",
    "#max density difference to store crossover\n",
    "delta_dens = 0.005\n",
    "# delta_dens = 0.05\n",
    "\n",
    "#max spice difference to store crossover\n",
    "delta_spice = 0.005\n",
    "# delta_spice = 0.05\n",
    "\n",
    "# max pressure difference to store crossover\n",
    "delta_press = 100\n",
    "# delta_press = 50\n",
    "\n",
    "#crossover distance range\n",
    "# dist = 50\n",
    "dist = 100\n",
    "\n",
    "#toggle to plot offsets profile by profile\n",
    "plot_profile = 0\n",
    "\n",
    "# choose whether to use ESPER or LIPHR for GLODAP crossover comparison\n",
    "# pH_alg = 'LIPHR'\n",
    "pH_alg = 'ESPER'\n",
    "\n",
    "\n",
    "# when making major changes, list version number here\n",
    "ver_n = '10' \n",
    "# v2 - moving interpolated spice and density calculation to post-PSAL and TEMP interpolation\n",
    "# v3 - fixed PH_25C calculation for float data, fixed in situ pH comparison (I think)\n",
    "# v4 - added back in SI and NO3 to DIC calculation - makes a difference apparently (also changes which points have valid data)\n",
    "# v5 - trying to do near-surface comparisons as well \n",
    "# v6 - working on full depth comparison that I will then separate by depth \n",
    "# v7 - trying to move code to parallel computing \n",
    "# v8 - now can choose whether to use ESPER or LIPHR to calculate GLODAP pH values for comparison \n",
    "# v9 - adding correction calculation option for nitrate, pH, dic\n",
    "# v10 - adding pHCalcTF flag to ESPER calculation - this instructs ESPER to calculate pH for agreement with DIC/TA, not spec pH \n",
    "\n",
    "run_str = str(dist) + 'km_' \\\n",
    "    + str(p_compare_min) + '_to_' + str(p_compare_max) + '_' + str(delta_press) + 'm_' + \\\n",
    "    str(delta_dens) + 'dens_' + str(delta_spice) + 'spice' + '_' + pH_alg + '_' + ver_n\n",
    "\n",
    "# Set the paths\n",
    "if adjustment is True:\n",
    "    argo_path = argo_path + '../Corrected/Sprof/'\n",
    "\n",
    "output_dir = argo_path + '../output_' + run_str + '/'\n",
    "data_dir = 'data/'\n",
    "\n",
    "#check directories exist\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "# Check for a glodap_offsets_plots directory, create if it does not exist\n",
    "offset_dir = output_dir + 'glodap_offset_plots/'\n",
    "if not os.path.isdir(offset_dir):\n",
    "    os.mkdir(offset_dir)\n",
    "\n",
    "\n",
    "glodap_file_offsets_dir = output_dir + 'glodap_file_offsets_' + run_str + '/'\n",
    "\n",
    "if not os.path.isdir(glodap_file_offsets_dir):\n",
    "    os.mkdir(glodap_file_offsets_dir)\n",
    "\n",
    "argo_path_interpolated = argo_path+'../interpolated_for_crossovers_' + run_str + '/'\n",
    "if not os.path.isdir(argo_path_interpolated):\n",
    "    os.mkdir(argo_path_interpolated)\n",
    "\n",
    "#add derived float file directory within argo_path\n",
    "argo_path_derived = argo_path+'../derived_for_crossovers_' + run_str + '/'\n",
    "if not os.path.isdir(argo_path_derived):\n",
    "    os.mkdir(argo_path_derived)\n",
    "\n",
    "glodap_offsets_filename = 'glodap_offsets_' + run_str + '.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs that usually will not change:\n",
    "\n",
    "#variables to do crossovers\n",
    "var_list_plot = ['PRES_ADJUSTED','TEMP_ADJUSTED','PSAL_ADJUSTED','DOXY_ADJUSTED','NITRATE_ADJUSTED',\n",
    "                 'DIC','pH_25C_TOTAL_ADJUSTED','PH_IN_SITU_TOTAL_ADJUSTED','PDENS']\n",
    "\n",
    "qc_data_fields = ['TEMP_ADJUSTED', 'PSAL_ADJUSTED', 'DOXY_ADJUSTED', 'NITRATE_ADJUSTED', \n",
    "                  'PRES_ADJUSTED', 'PH_IN_SITU_TOTAL_ADJUSTED']\n",
    "\n",
    "bgc_data_fields = ['DOXY_ADJUSTED', 'NITRATE_ADJUSTED', 'PH_IN_SITU_TOTAL_ADJUSTED']\n",
    "\n",
    "#variables to save to derived file\n",
    "derived_list = ['TEMP_ADJUSTED', 'PSAL_ADJUSTED', 'DOXY_ADJUSTED', 'NITRATE_ADJUSTED', 'PH_IN_SITU_TOTAL_ADJUSTED',\n",
    "            'pH_25C_TOTAL_ADJUSTED', 'PDENS', 'spice', 'PRES_ADJUSTED', 'DIC','TALK_LIAR']\n",
    "\n",
    "# variables to do interpolation on:\n",
    "interpolation_list = ['TEMP_ADJUSTED', 'PSAL_ADJUSTED', 'DOXY_ADJUSTED', 'NITRATE_ADJUSTED', 'PH_IN_SITU_TOTAL_ADJUSTED',\n",
    "            'pH_25C_TOTAL_ADJUSTED', 'PRES_ADJUSTED', 'DIC','TALK_LIAR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and process GLODAP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0257247/GLODAPv2.2022_Merged_Master_File.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smb-uh/UHM_Ocean_BGC_Group Dropbox/Seth Bushinsky/Work/Manuscripts/2022_07 Deep O2 Bias/argo_deep_o2_bias/functions/float_data_processing.py:36: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gdap = pd.read_csv(save_dir+'GLODAPv2.'+str(year)+'_Merged_Master_File.csv')\n",
      "/var/folders/7r/4f_w_nb56llcwh96t_pjq_qh0000gn/T/ipykernel_84568/2796635500.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdap.G2longitude[gdap.G2longitude < 0.] = gdap.G2longitude[gdap.G2longitude < 0.] + 360.\n",
      "/var/folders/7r/4f_w_nb56llcwh96t_pjq_qh0000gn/T/ipykernel_84568/2796635500.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdap[v][naninds] = np.nan\n",
      "/Users/smb-uh/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/gsw/_wrapped_ufuncs.py:3394: RuntimeWarning: overflow encountered in sigma0\n",
      "  return _gsw_ufuncs.sigma0(SA, CT)\n",
      "/Users/smb-uh/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/gsw/_wrapped_ufuncs.py:4055: RuntimeWarning: overflow encountered in spiciness0\n",
      "  return _gsw_ufuncs.spiciness0(SA, CT)\n",
      "/Users/smb-uh/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/gsw/_wrapped_ufuncs.py:4055: RuntimeWarning: invalid value encountered in spiciness0\n",
      "  return _gsw_ufuncs.spiciness0(SA, CT)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: CO2SYS took >20 iterations to converge. The corresponding estimate(s) will be NaN. This typically happens when ESPER_NN is very poorly suited for estimating water with the given properties (e.g., very high or low salinity or estimates in marginal seas).\n",
      "Warning: CO2SYS took >20 iterations to converge. The corresponding estimate(s) will be NaN. This typically happens when ESPER_LIR is very poorly suited for estimating water with the given properties (e.g., very high or low salinity or estimates in marginal seas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/4f_w_nb56llcwh96t_pjq_qh0000gn/T/ipykernel_84568/2796635500.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdap.pH_in_situ_total[np.isnan(gdap.G2phts25p0)] = np.nan\n",
      "/Users/smb-uh/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/autograd/tracer.py:48: RuntimeWarning: invalid value encountered in log\n",
      "  return f_raw(*args, **kwargs)\n",
      "/Users/smb-uh/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/PyCO2SYS/equilibria/p1atm.py:419: RuntimeWarning: overflow encountered in power\n",
      "  K1 = 10.0**-pK1  # this is on the NBS scale\n",
      "/Users/smb-uh/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/PyCO2SYS/equilibria/p1atm.py:479: RuntimeWarning: overflow encountered in power\n",
      "  K1 = 10.0**-pK1  # this is on the NBS scale\n",
      "/Users/smb-uh/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/PyCO2SYS/equilibria/p1atm.py:761: RuntimeWarning: invalid value encountered in sqrt\n",
      "  -13.6416 + 1.176949 * TempK**0.5 - 0.02860785 * TempK + 545.4834 / TempK\n",
      "/Users/smb-uh/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/PyCO2SYS/equilibria/p1atm.py:765: RuntimeWarning: invalid value encountered in sqrt\n",
      "  + 0.0090226468 * TempK**0.5\n",
      "/Users/smb-uh/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/PyCO2SYS/equilibria/p1atm.py:770: RuntimeWarning: invalid value encountered in sqrt\n",
      "  0.004669309 - 0.0001691742 * TempK**0.5 - 0.5677934 / TempK\n",
      "/Users/smb-uh/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/autograd/tracer.py:48: RuntimeWarning: invalid value encountered in log10\n",
      "  return f_raw(*args, **kwargs)\n",
      "/var/folders/7r/4f_w_nb56llcwh96t_pjq_qh0000gn/T/ipykernel_84568/2796635500.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdap.pH_25C_TOTAL_ADJUSTED[np.isnan(gdap.G2phts25p0)]=np.nan\n"
     ]
    }
   ],
   "source": [
    "gdap = fl.get_glodap(data_dir, year = 2022)\n",
    "gdap.G2longitude[gdap.G2longitude < 0.] = gdap.G2longitude[gdap.G2longitude < 0.] + 360.\n",
    "#set flagged data to NaN (is this needed? or masked array better?)\n",
    "flagvars = ['G2salinity','G2oxygen','G2nitrate','G2tco2','G2talk','G2phts25p0']\n",
    "\n",
    "for v in flagvars:\n",
    "    flag = v+'f'\n",
    "    naninds = gdap[flag]!=2\n",
    "    gdap[v][naninds] = np.nan\n",
    "\n",
    "# GLODAP derived variables: density, MLD and pH\n",
    "\n",
    "#calc potential density\n",
    "gdap['sigma0_calculated'] = carbon_utilities.sigma0(gdap.G2salinity.values,gdap.G2temperature.values,\n",
    "                                  gdap.G2longitude.values,gdap.G2latitude.values,gdap.G2pressure.values)\n",
    "#calculate spice\n",
    "gdap['spice'] = carbon_utilities.spiciness0(gdap.G2salinity.values,gdap.G2temperature.values,\n",
    "                                  gdap.G2longitude.values,gdap.G2latitude.values,gdap.G2pressure.values)\n",
    "\n",
    "#pH from LIPHR\n",
    "# calculate LIPHR pH at Glodap points below 1480 m and above 2020m (V: where does the depth restriction come in?)\n",
    "LIPHR_path = liar_dir\n",
    "Coordinates = np.stack((gdap.G2longitude.values.flatten(), \n",
    "                        gdap.G2latitude.values.flatten(), \n",
    "                        gdap.G2pressure.values.flatten()),\n",
    "                        axis=1)\n",
    "Measurements = np.stack((gdap.G2salinity.values.flatten(), \n",
    "                         gdap.G2temperature.values.flatten(), \n",
    "                         gdap.G2oxygen.values.flatten()),\n",
    "                         axis=1)\n",
    "\n",
    "if pH_alg=='LIPHR':           \n",
    "    MeasIDVec = [1, 7, 6]\n",
    "    results = carbon_utilities.LIPHR_matlab(LIPHR_path,\n",
    "                                        Coordinates.tolist(),\n",
    "                                        Measurements.tolist(),\n",
    "                                        MeasIDVec, \n",
    "                                        OAAdjustTF = False)            \n",
    "elif pH_alg=='ESPER':\n",
    "    MeasIDVec_ESPER = [1, 2, 6] # S, T, O2 - different numbering than v2 LIRs\n",
    "    Equations = 7 # for ESPER - asking to use equation w/ S, T, and O2 only \n",
    "    DesiredVariables = [3] # in situ pH on total scale \n",
    "\n",
    "    # calculate decimal_year for ESPER\n",
    "    da = gdap.datetime\n",
    "    decimal_year = da.dt.year + (da.dt.dayofyear - 1 + (da.dt.hour * 3600 + da.dt.minute * 60 + da.dt.second) / 86400) / (365 + da.dt.is_leap_year)\n",
    "    results = carbon_utilities.ESPER_mixed_matlab(LIPHR_path,\n",
    "                                                    DesiredVariables,\n",
    "                                                    Coordinates.tolist(),\n",
    "                                                    Measurements.tolist(),\n",
    "                                                    MeasIDVec_ESPER,\n",
    "                                                    Equations, \n",
    "                                                    decimal_year.values.tolist(), \n",
    "                                                    0, 1)\n",
    "gdap['pH_in_situ_total'] = results\n",
    "gdap.pH_in_situ_total[np.isnan(gdap.G2phts25p0)] = np.nan\n",
    "# gdap pH 25C \n",
    "gdap['pH_25C_TOTAL_ADJUSTED'] = carbon_utilities.co2sys_pH25C(2300.,gdap.pH_in_situ_total,gdap.G2temperature,\n",
    "                                                         gdap.G2salinity,gdap.G2pressure)\n",
    "#set pH to nan where there was no original pH data from GLODAP\n",
    "gdap.pH_25C_TOTAL_ADJUSTED[np.isnan(gdap.G2phts25p0)]=np.nan\n",
    "\n",
    "#rename GLODAP comparison variables to match argo\n",
    "gdap = gdap.rename(columns={'G2longitude':'LONGITUDE', 'G2latitude':'LATITUDE', 'G2pressure':'PRES_ADJUSTED',\n",
    "                            'G2temperature':'TEMP_ADJUSTED','G2salinity':'PSAL_ADJUSTED', \n",
    "                            'G2oxygen':'DOXY_ADJUSTED','G2nitrate':'NITRATE_ADJUSTED', 'G2tco2':'DIC', \n",
    "                            'G2talk':'TALK_LIAR', 'G2MLD':'MLD','G2o2sat':'o2sat', 'G2PTMP':'PTMP', \n",
    "                            'pH_in_situ_total':'PH_IN_SITU_TOTAL_ADJUSTED','sigma0_calculated':'PDENS'})\n",
    "\n",
    "gdap['obs_index']=gdap.reset_index().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing float file 5904397_Sprof.nc\n",
      "5904397_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904397\n"
     ]
    }
   ],
   "source": [
    "# Testing, can delete \n",
    "\n",
    "argo_file = '5904397_Sprof.nc'\n",
    "LIAR_path = liar_dir\n",
    "\n",
    "adjustment = True\n",
    "\n",
    "# testing, can delete \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "import PyCO2SYS as pyco2\n",
    "import carbon_utils\n",
    "\n",
    "\n",
    "print('Processing float file '+ argo_file)\n",
    "argo_n = xr.load_dataset(argo_path+argo_file)\n",
    "argo_n = argo_n.set_coords(('PRES_ADJUSTED','LATITUDE','LONGITUDE','JULD'))\n",
    "\n",
    "wmo_n = argo_n.PLATFORM_NUMBER.values.astype(int)[0]\n",
    "# wmo_list.append(wmo_n)\n",
    "\n",
    "nprof_n = argo_n.dims['N_PROF']\n",
    "\n",
    "p_interp_min = p_interp[0]\n",
    "p_interp_max = p_interp[-1]\n",
    "\n",
    "#   set bad data and possibly bad data to NaN \n",
    "for q in qc_data_fields:      \n",
    "    if q in argo_n.keys():\n",
    "        qc_val = argo_n[q+'_QC'].values.astype('float')\n",
    "        \n",
    "        # for some reason the .where statement was not filtering out bad values. \n",
    "        #This code is now changing QC values of 3 or 4 to nans, not sure if it is the best approach\n",
    "        #argo_n[q].where(np.logical_and(qc_val<3.,qc_val>4.))\n",
    "        argo_n[q].values[np.logical_or(qc_val==4,qc_val==3)]=np.nan\n",
    "        \n",
    "        #check for any Inf values not included in QC flag and set to NaN\n",
    "        argo_n[q].values[np.isinf(argo_n[q]).values] = np.nan\n",
    "    \n",
    "# check for interpolated profile positions (under ice) and set all BGC data to nan\n",
    "qc_val = argo_n['POSITION_QC'].values.astype('float')\n",
    "for b in bgc_data_fields:\n",
    "    if b in argo_n.keys() and np.any(qc_val==8):\n",
    "        naninds = np.argwhere(qc_val==8)[:,0]\n",
    "        argo_n[b][naninds,:] = np.nan\n",
    "\n",
    "# we are currently processing floats that have no valid biogeochemical data. \n",
    "#Should check to see if data in key \n",
    "#original bgc parameters (O2, NO3, pH) is valid and skip the rest if not\n",
    "bgc_valid = 0\n",
    "for b in bgc_data_fields:\n",
    "    if b in argo_n.keys() and np.any(~np.isnan(argo_n[b])):\n",
    "        bgc_valid = bgc_valid+1\n",
    "if bgc_valid >=1:\n",
    "    print(argo_file + ' has valid BGC data')\n",
    "else:\n",
    "    print(argo_file + ' has no valid BGC data')\n",
    "    # return\n",
    "\n",
    "argo_n['PDENS'] = (['N_PROF','N_LEVELS'],np.empty(argo_n.PRES_ADJUSTED.shape)) #nprof x nlevel\n",
    "argo_n.PDENS[:] = np.nan\n",
    "argo_n['spice'] = (['N_PROF','N_LEVELS'],np.empty(argo_n.PRES_ADJUSTED.shape)) #nprof x nlevel\n",
    "argo_n.spice[:] = np.nan\n",
    "\n",
    "#initialise interpolated dataset for float\n",
    "nan_interp = np.empty((nprof_n,p_interp.shape[0]))\n",
    "nan_interp[:] = np.nan\n",
    "argo_interp_n = xr.Dataset()\n",
    "argo_interp_n['wmo'] = (['N_PROF'],np.repeat(wmo_n,nprof_n))\n",
    "argo_interp_n['profile'] = (['N_PROF'],argo_n.CYCLE_NUMBER.data) # added .data \n",
    "argo_interp_n['juld'] = (['N_PROF'],argo_n.JULD_LOCATION.data)\n",
    "#add lat -lons to Dataset\n",
    "argo_interp_n['LATITUDE']  = (['N_PROF'],argo_n.LATITUDE.data)\n",
    "argo_interp_n['LONGITUDE']  = (['N_PROF'],argo_n.LONGITUDE.data)\n",
    "argo_interp_n['num_var'] = (['N_PROF'],np.zeros((nprof_n))) # changed from np.empty to np.zeros to avoid filling array with random large numbers\n",
    "for v in derived_list: # all the variables that will be saved out in the derived and interpolated files\n",
    "    argo_interp_n[v] = (['N_PROF','N_LEVELS'],np.copy(nan_interp))\n",
    "\n",
    "if adjustment is True:\n",
    "    impact_n = xr.load_dataset(argo_path + argo_file[0:7] + '_impact.nc')\n",
    "    argo_n['DOXY_ADJUSTED'] = argo_n['DOXY_ADJUSTED'] + impact_n.mean_O2_offset\n",
    "    if 'NITRATE_ADJUSTED' in argo_n.keys():\n",
    "        argo_n['NITRATE_ADJUSTED'] = argo_n['NITRATE_ADJUSTED'] + impact_n.mean_nitrate_impact_change\n",
    "\n",
    "#check first if PH_IN_SITU_TOTAL_ADJUSTED exists\n",
    "if 'PH_IN_SITU_TOTAL_ADJUSTED' in argo_n.keys() and np.any(~np.isnan(argo_n.PH_IN_SITU_TOTAL_ADJUSTED)):\n",
    "    \n",
    "    print('Calculating TALK, DIC and pH 25C correction for float '+str(wmo_n))\n",
    "    \n",
    "    #initialise pH 25c and DIC variables - could do this only if float has pH\n",
    "    argo_n['TALK_LIAR'] = (['N_PROF','N_LEVELS'],np.empty(argo_n.PRES_ADJUSTED.shape)) #nprof x nlevel\n",
    "    argo_n.TALK_LIAR[:] = np.nan\n",
    "    argo_n['pH_25C_TOTAL_ADJUSTED'] = (['N_PROF','N_LEVELS'],np.empty(argo_n.PRES_ADJUSTED.shape)) #nprof x nlevel\n",
    "    argo_n.pH_25C_TOTAL_ADJUSTED[:] = np.nan\n",
    "    argo_n['DIC'] = (['N_PROF','N_LEVELS'],np.empty(argo_n.PRES_ADJUSTED.shape)) #nprof x nlevel\n",
    "    argo_n.DIC[:] = np.nan\n",
    "\n",
    "    ##### Calc float TALK       \n",
    "    #repeat lats, lons to match pressure shape\n",
    "    lons_rep = np.tile(argo_n.LONGITUDE.values,(argo_n.PRES_ADJUSTED.shape[1],1)).T\n",
    "    lats_rep = np.tile(argo_n.LATITUDE.values,(argo_n.PRES_ADJUSTED.shape[1],1)).T\n",
    "\n",
    "    #set Si and PO4 inputs\n",
    "    #if nitrate, then use redfield for Si and PO4?, otherwise set to 0    \n",
    "    if 'NITRATE_ADJUSTED' in argo_n.keys():\n",
    "        SI = argo_n.NITRATE_ADJUSTED*2.5\n",
    "        SI.where(~np.isnan(SI), 0)\n",
    "        PO4 = argo_n.NITRATE_ADJUSTED/16\n",
    "        PO4.where(~np.isnan(PO4),0)\n",
    "        Coordinates = np.stack((lons_rep.flatten(), \n",
    "                        lats_rep.flatten(), \n",
    "                        argo_n.PRES_ADJUSTED.values.flatten()),\n",
    "                        axis=1)\n",
    "        Measurements = np.stack((argo_n.PSAL_ADJUSTED.values.flatten(), \n",
    "                            argo_n.TEMP_ADJUSTED.values.flatten(), \n",
    "                            argo_n.NITRATE_ADJUSTED.values.flatten(), \n",
    "                            argo_n.DOXY_ADJUSTED.values.flatten()),\n",
    "                            axis=1)\n",
    "        MeasIDVec = [1, 7, 3, 6]\n",
    "\n",
    "    else:\n",
    "        SI = np.zeros((argo_n.PH_IN_SITU_TOTAL_ADJUSTED.shape))\n",
    "        PO4 = np.zeros((argo_n.PH_IN_SITU_TOTAL_ADJUSTED.shape))\n",
    "        Coordinates = np.stack((lons_rep.flatten(), \n",
    "                        lats_rep.flatten(), \n",
    "                        argo_n.PRES_ADJUSTED.values.flatten()),\n",
    "                        axis=1)\n",
    "        Measurements = np.stack((argo_n.PSAL_ADJUSTED.values.flatten(), \n",
    "                            argo_n.TEMP_ADJUSTED.values.flatten(),\n",
    "                            argo_n.DOXY_ADJUSTED.values.flatten()),\n",
    "                            axis=1)\n",
    "        MeasIDVec = [1, 7, 6]                            \n",
    "\n",
    "\n",
    "    results = carbon_utils.LIAR_matlab(LIAR_path,\n",
    "                                            Coordinates.tolist(),\n",
    "                                            Measurements.tolist(),\n",
    "                                            MeasIDVec,\n",
    "                                            VerboseTF=False)                                  \n",
    "\n",
    "    argo_n['TALK_LIAR'] = (['N_PROF','N_LEVELS'],\n",
    "                            np.reshape(np.asarray(results),argo_n.PH_IN_SITU_TOTAL_ADJUSTED.shape))\n",
    "\n",
    "    # Keep DIC bc I might want it for crossover comparison\n",
    "    ##### Calculate float pH at 25C, DIC and apply bias corr\n",
    "    results = pyco2.sys(\n",
    "            par1=argo_n.TALK_LIAR, \n",
    "            par2=argo_n.PH_IN_SITU_TOTAL_ADJUSTED,\n",
    "            par1_type=1,\n",
    "            par2_type=3,\n",
    "            temperature=argo_n.TEMP_ADJUSTED, \n",
    "            pressure=argo_n.PRES_ADJUSTED, \n",
    "            salinity=argo_n.PSAL_ADJUSTED, \n",
    "            temperature_out=25.,#*np.ones(argo_n.PRES_ADJUSTED.shape), #fixed 25C temperature\n",
    "            pressure_out=argo_n.PRES_ADJUSTED,\n",
    "            total_silicate=SI,\n",
    "            total_phosphate=PO4,\n",
    "            opt_pH_scale = 1, #total\n",
    "            opt_k_carbonic=10, #Lueker et al. 2000\n",
    "            opt_k_bisulfate=1, # Dickson 1990 (Note, matlab co2sys combines KSO4 with TB. option 3 = KSO4 of Dickson & TB of Lee 2010)\n",
    "            opt_total_borate=2, # Lee et al. 2010\n",
    "            opt_k_fluoride=2, # Perez and Fraga 1987\n",
    "            opt_buffers_mode=1,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    argo_n['pH_25C_TOTAL_ADJUSTED'] = (['N_PROF','N_LEVELS'],carbon_utils.co2sys_pH25C(argo_n.TALK_LIAR,\n",
    "                                                argo_n.PH_IN_SITU_TOTAL_ADJUSTED,\n",
    "                                                argo_n.TEMP_ADJUSTED,\n",
    "                                                argo_n.PSAL_ADJUSTED,\n",
    "                                                argo_n.PRES_ADJUSTED))\n",
    "\n",
    "    # if applying adjustment to pH - apply it to pH 25C, then recalculate pH insitu, then calculate DIC\n",
    "    if adjustment is True:\n",
    "        argo_n['pH_25C_TOTAL_ADJUSTED'] = argo_n['pH_25C_TOTAL_ADJUSTED'] + impact_n.mean_pH_impact_change\n",
    "\n",
    "        results = pyco2.sys(\n",
    "            par1=argo_n.TALK_LIAR, \n",
    "            par2=argo_n.pH_25C_TOTAL_ADJUSTED,\n",
    "            par1_type=1,\n",
    "            par2_type=3,\n",
    "            temperature=25, \n",
    "            pressure=argo_n.PRES_ADJUSTED, \n",
    "            salinity=argo_n.PSAL_ADJUSTED, \n",
    "            temperature_out=argo_n.TEMP_ADJUSTED,#*np.ones(argo_n.PRES_ADJUSTED.shape), #fixed 25C temperature\n",
    "            pressure_out=argo_n.PRES_ADJUSTED,\n",
    "            total_silicate=SI,\n",
    "            total_phosphate=PO4,\n",
    "            opt_pH_scale = 1, #total\n",
    "            opt_k_carbonic=10, #Lueker et al. 2000\n",
    "            opt_k_bisulfate=1, # Dickson 1990 (Note, matlab co2sys combines KSO4 with TB. option 3 = KSO4 of Dickson & TB of Lee 2010)\n",
    "            opt_total_borate=2, # Lee et al. 2010\n",
    "            opt_k_fluoride=2, # Perez and Fraga 1987\n",
    "            opt_buffers_mode=1,\n",
    "            )\n",
    "        argo_n['DIC'] = (['N_PROF','N_LEVELS'],results['dic'])  \n",
    "    else: # otherwise, just save DIC with no adjustment \n",
    "        argo_n['DIC'] = (['N_PROF','N_LEVELS'],results['dic'])  \n",
    "\n",
    "##### now calc potential density, save, and interpolate data for comparison\n",
    "for p in range(nprof_n):\n",
    "    #pressure for profile\n",
    "    p_prof = argo_n.PRES_ADJUSTED[p,:]\n",
    "    \n",
    "    # For interpolated data, shouldn't calculate pdens and spice and then interpolate - \n",
    "    # should interpolate psal and temp and then calculate spice and pdens\n",
    "    # Do both so that you are able to have PDENS and spice in the derived files too (do I need them?)\n",
    "    argo_n['PDENS'][p,:] = carbon_utils.sigma0(argo_n.PSAL_ADJUSTED[p,:].values,\n",
    "                                                argo_n.TEMP_ADJUSTED[p,:].values,\n",
    "                                                argo_n.LONGITUDE[p].values,\n",
    "                                                argo_n.LATITUDE[p].values,\n",
    "                                                argo_n.PRES_ADJUSTED[p,:].values)\n",
    "    argo_n['spice'][p,:] = carbon_utils.spiciness0(argo_n.PSAL_ADJUSTED[p,:].values,\n",
    "                                                argo_n.TEMP_ADJUSTED[p,:].values,\n",
    "                                                argo_n.LONGITUDE[p].values,\n",
    "                                                argo_n.LATITUDE[p].values,\n",
    "                                                argo_n.PRES_ADJUSTED[p,:].values)\n",
    "\n",
    "    #for each profile get pressure values > p_interp_min db\n",
    "    p100 = p_prof[p_prof>p_interp_min].values\n",
    "        \n",
    "    #if only 1 value of pressure or if there is not valid profile data down to p-max, continue loop\n",
    "    if (len(p100) <= 1) or (np.nanmax(p100)<p_interp_min):\n",
    "        continue\n",
    "    \n",
    "    # # check for the presence of large gaps in the float profile data - can figure out how to deal with them once you know their prevalence \n",
    "    # if max(np.diff(p100))>125:\n",
    "    #     print(np.diff(p100))\n",
    "    #     data_out = p100.reshape(-1,1)\n",
    "    #     df = pd.DataFrame(data_out, columns = ['Pressure prior to interpolation'])\n",
    "    #     df.to_csv(argo_path_interpolated + str(wmo_n) + '_' + str(p) + '.csv', index=False)\n",
    "\n",
    "    #find which crossover variables exist in main float file\n",
    "    var_list_n = []\n",
    "    for vname in interpolation_list:\n",
    "        if (vname in argo_n.keys()) and (np.any(~np.isnan(argo_n[vname]))):\n",
    "            var_list_n.append(vname)\n",
    "            \n",
    "    argo_interp_n['num_var'][p] = len(var_list_n) \n",
    "    \n",
    "    for var in var_list_n:\n",
    "        var100 = argo_n[var][p,p_prof>p_interp_min]\n",
    "\n",
    "        #if there are non-unique pressure values, \n",
    "        #then grab only unique pressure values and matching data points\n",
    "        if len(p100)>len(np.unique(p100)):\n",
    "            p100u,unique_inds = np.unique(p100, return_index=True)\n",
    "            var100u = var100[unique_inds]\n",
    "        else:\n",
    "            p100u = p100\n",
    "            var100u = var100\n",
    "            \n",
    "        #interpolate 1d profile data onto p_interp levels \n",
    "        # use valid var data from p_interp_min to p_interp_max OR maximum valid pressure \n",
    "        #(greater than minimum comparison pressure)\n",
    "\n",
    "        if len(p100u[~np.isnan(var100u.values)])>1 and \\\n",
    "            (np.nanmax(p100u[~np.isnan(var100u.values)])>p_interp_min) and \\\n",
    "            (np.nanmin(p100u[~np.isnan(var100u.values)])<p_interp_max):\n",
    "            \n",
    "            #interpolation function\n",
    "            f = interpolate.interp1d(p100u[~np.isnan(var100u.values)],var100u[~np.isnan(var100u.values)])\n",
    "            \n",
    "            #check if non-NaN data does not extend down to p_interp_max\n",
    "            if np.logical_and((p100u[~np.isnan(var100u.values)][-1]<p_interp_max),\n",
    "                                (p100u[~np.isnan(var100u.values)][0]>p_interp_min)):\n",
    "                pmin_ind = np.argwhere(p_interp>p100u[~np.isnan(var100u.values)][0])[0][0]\n",
    "                pmax_ind = np.argwhere(p_interp>p100u[~np.isnan(var100u.values)][-1])[0][0]\n",
    "                #if  p100u[~np.isnan(var100u)][0]>p_interp_min:                   \n",
    "                var_interp_p = f(p_interp[pmin_ind:pmax_ind])\n",
    "                #assign interpolated variables to array \n",
    "                argo_interp_n[var][p,pmin_ind:pmax_ind] = var_interp_p\n",
    "                \n",
    "            elif p100u[~np.isnan(var100u.values)][-1]<p_interp_max:\n",
    "                pmax_ind = np.argwhere(p_interp>p100u[~np.isnan(var100u.values)][-1])[0][0]\n",
    "                var_interp_p = f(p_interp[:pmax_ind])\n",
    "                #assign interpolated variables to array \n",
    "                argo_interp_n[var][p,:pmax_ind] = var_interp_p\n",
    "                    \n",
    "            elif p100u[~np.isnan(var100u.values)][0]>p_interp_min:\n",
    "                pmin_ind = np.argwhere(p_interp>p100u[~np.isnan(var100u.values)][0])[0][0]\n",
    "                var_interp_p = f(p_interp[pmin_ind:])\n",
    "                #assign interpolated variables to array \n",
    "                argo_interp_n[var][p,pmin_ind:] = var_interp_p\n",
    "                \n",
    "            else:\n",
    "                var_interp_p = f(p_interp)\n",
    "                #assign interpolated variables to array \n",
    "                argo_interp_n[var][p,:] = var_interp_p\n",
    "        \n",
    "            # check for gaps in the original data greater than 125 m\n",
    "            gap_index= (np.diff(p100u)>125)\n",
    "\n",
    "            # if any values of gap_index are true, loop through and set values of interpolated data that are between value of large gaps to nan \n",
    "            if any(gap_index):\n",
    "                temp_var = argo_interp_n[var][p,:]\n",
    "                data_out = temp_var.values.reshape(-1,1)\n",
    "                combined_data = np.hstack((p_interp.reshape(-1, 1), data_out))\n",
    "                df = pd.DataFrame(combined_data, columns = ['Pressure', 'Oxygen'])\n",
    "                df.to_csv(argo_path_interpolated + str(wmo_n) + '_' + str(p) + '.csv', index=False)\n",
    "\n",
    "                # print(argo_interp_n[var][p,:])\n",
    "                for idx, gi in enumerate(gap_index):\n",
    "                    if gi:\n",
    "                        # print(p100u[idx])\n",
    "                        # print(p100u[idx+1])\n",
    "                        argo_interp_n[var][p,np.logical_and(p_interp>p100u[idx],p_interp<p100u[idx+1])] = np.nan\n",
    "                temp_var = argo_interp_n[var][p,:]\n",
    "                data_out = temp_var.values.reshape(-1,1)\n",
    "                combined_data = np.hstack((p_interp.reshape(-1, 1), data_out))\n",
    "                df = pd.DataFrame(combined_data, columns = ['Pressure', 'Oxygen'])\n",
    "                df.to_csv(argo_path_interpolated + str(wmo_n) + '_' + str(p) + '_after_removal.csv', index=False)\n",
    "\n",
    "#             else: \n",
    "            # print('profile data not deep enough to interpolate ' + str(p) + ' ' +  var)\n",
    "            #                       str(np.nanmax(p100u[~np.isnan(var100u.values)])))\n",
    "            # print('values greater than min ' + str(var100u[p100u>p_interp_min].values))\n",
    "\n",
    "# loop through profiles again to calculate PDENS and spice for interpolated dataset\n",
    "for p in range(nprof_n):\n",
    "    #pressure for profile\n",
    "    p_prof = argo_interp_n.PRES_ADJUSTED[p,:]\n",
    "\n",
    "    # For interpolated data, shouldn't calculate pdens and spice and then interpolate - \n",
    "    # should interpolate psal and temp and then calculate spice and pdens\n",
    "    # Do both so that you are able to have PDENS and spice in the derived files too (do I need them?)\n",
    "    argo_interp_n['PDENS'][p,:] = carbon_utils.sigma0(argo_interp_n.PSAL_ADJUSTED[p,:].values,\n",
    "                                                argo_interp_n.TEMP_ADJUSTED[p,:].values,\n",
    "                                                argo_interp_n.LONGITUDE[p].values,\n",
    "                                                argo_interp_n.LATITUDE[p].values,\n",
    "                                                argo_interp_n.PRES_ADJUSTED[p,:].values)\n",
    "    argo_interp_n['spice'][p,:] = carbon_utils.spiciness0(argo_interp_n.PSAL_ADJUSTED[p,:].values,\n",
    "                                                argo_interp_n.TEMP_ADJUSTED[p,:].values,\n",
    "                                                argo_interp_n.LONGITUDE[p].values,\n",
    "                                                    argo_interp_n.LATITUDE[p].values,\n",
    "                                                    argo_interp_n.PRES_ADJUSTED[p,:].values)\n",
    "    \n",
    "#create new dataset with relevant crossover variables only\n",
    "argo_n_derived = xr.Dataset()\n",
    "argo_n_derived['wmo'] = wmo_n\n",
    "argo_n_derived['CYCLE_NUMBER'] = (['N_PROF'],argo_n.CYCLE_NUMBER.values)\n",
    "argo_n_derived['LONGITUDE'] = (['N_PROF'],argo_n.LONGITUDE.values)\n",
    "argo_n_derived['LATITUDE'] = (['N_PROF'],argo_n.LATITUDE.values)\n",
    "argo_n_derived['JULD_LOCATION'] = (['N_PROF'],argo_n.JULD_LOCATION.values)\n",
    "for var in derived_list:\n",
    "    if var in argo_n.keys():\n",
    "        argo_n_derived[var] = (['N_PROF','N_LEVELS'],argo_n[var].values)\n",
    "# argo_n_derived.to_netcdf(argo_path_derived+str(wmo_n)+'_derived.nc')\n",
    "\n",
    "# argo_interp_n.to_netcdf(argo_path_interpolated+str(wmo_n)+'_interpolated.nc')\n",
    "\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing float file 5904663_Sprof.ncProcessing float file 4903026_Sprof.nc\n",
      "\n",
      "Processing float file 5904859_Sprof.nc\n",
      "Processing float file 5904657_Sprof.nc\n",
      "Processing float file 1902303_Sprof.nc\n",
      "Processing float file 5904693_Sprof.nc\n",
      "Processing float file 4903459_Sprof.nc\n",
      "Processing float file 5904660_Sprof.nc\n",
      "Processing float file 5904682_Sprof.nc\n",
      "Processing float file 5904188_Sprof.nc\n",
      "Processing float file 5904468_Sprof.nc\n",
      "Processing float file 5904841_Sprof.nc\n",
      "Processing float file 5903893_Sprof.nc\n",
      "Processing float file 5904471_Sprof.nc\n",
      "Processing float file 5904763_Sprof.nc\n",
      "Processing float file 5904675_Sprof.nc\n",
      "Processing float file 5904854_Sprof.nc\n",
      "Processing float file 1902384_Sprof.nc\n",
      "4903459_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 4903459\n",
      "5904675_Sprof.nc has valid BGC data\n",
      "1902384_Sprof.nc has valid BGC data\n",
      "5904657_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904675\n",
      "5904663_Sprof.nc has valid BGC data\n",
      "1902303_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 1902384\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904657\n",
      "5903893_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904663\n",
      "5904660_Sprof.nc has valid BGC data\n",
      "5904841_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 1902303\n",
      "5904471_Sprof.nc has valid BGC data\n",
      "5904763_Sprof.nc has valid BGC data\n",
      "5904682_Sprof.nc has valid BGC data\n",
      "5904188_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5903893\n",
      "5904693_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904660\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904841\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904471\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904763\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904682\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904188\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904693\n",
      "5904468_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904468\n",
      "5904854_Sprof.nc has valid BGC data\n",
      "5904859_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904854\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904859\n",
      "4903026_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 4903026\n",
      "Processing float file 4903462_Sprof.nc\n",
      "4903462_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 4903462\n",
      "Processing float file 1902385_Sprof.nc\n",
      "1902385_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 1902385\n",
      "Processing float file 1902304_Sprof.nc\n",
      "1902304_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 1902304\n",
      "Processing float file 5904661_Sprof.nc\n",
      "5904661_Sprof.nc has valid BGC data\n",
      "Processing float file 5904678_Sprof.nc\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904661\n",
      "5904678_Sprof.nc has valid BGC data\n",
      "Processing float file 5904395_Sprof.nc\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904678\n",
      "5904395_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904395\n",
      "Processing float file 5904842_Sprof.nc\n",
      "Processing float file 5904695_Sprof.nc\n",
      "Processing float file 5904658_Sprof.nc\n",
      "Processing float file 5904472_Sprof.nc\n",
      "5904842_Sprof.nc has valid BGC data\n",
      "5904695_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904842\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904695\n",
      "5904658_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904658\n",
      "5904472_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904472\n",
      "Processing float file 5904765_Sprof.nc\n",
      "Processing float file 5904683_Sprof.nc\n",
      "Processing float file 5904673_Sprof.nc\n",
      "5904765_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904765\n",
      "5904683_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904683\n",
      "5904673_Sprof.nc has valid BGC data\n",
      "Processing float file 5904185_Sprof.nc\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904673\n",
      "5904185_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904185\n",
      "Processing float file 5904469_Sprof.nc\n",
      "5904469_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904469\n",
      "Processing float file 5904856_Sprof.nc\n",
      "5904856_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904856\n",
      "Processing float file 5904982_Sprof.nc\n",
      "5904982_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904982\n",
      "Processing float file 4903486_Sprof.nc\n",
      "4903486_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 4903486\n",
      "Processing float file 4903365_Sprof.nc\n",
      "4903365_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 4903365\n",
      "Processing float file 2903451_Sprof.nc\n",
      "2903451_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 2903451\n",
      "Processing float file 5904674_Sprof.nc\n",
      "5904674_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904674\n",
      "Processing float file 1902383_Sprof.nc\n",
      "1902383_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 1902383\n",
      "Processing float file 5904766_Sprof.nc\n",
      "5904766_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904766\n",
      "Processing float file 5904685_Sprof.nc\n",
      "5904685_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904685\n",
      "Processing float file 5904662_Sprof.nc\n",
      "Processing float file 5904474_Sprof.nc\n",
      "5904662_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904662\n",
      "5904474_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904474\n",
      "Processing float file 5904659_Sprof.nc\n",
      "5904659_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904659\n",
      "Processing float file 5904679_Sprof.nc\n",
      "5904679_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904679\n",
      "Processing float file 5904761_Sprof.nc\n",
      "Processing float file 5904844_Sprof.nc\n",
      "5904761_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904761\n",
      "5904844_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904844\n",
      "Processing float file 5904397_Sprof.nc\n",
      "Processing float file 5904470_Sprof.nc\n",
      "5904397_Sprof.nc has valid BGC data\n",
      "5904470_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904470\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904397\n",
      "Processing float file 5904187_Sprof.nc\n",
      "5904187_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904187\n",
      "Processing float file 5904984_Sprof.nc\n",
      "5904984_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904984\n",
      "Processing float file 4903456_Sprof.nc\n",
      "4903456_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 4903456\n",
      "Processing float file 5905077_Sprof.nc\n",
      "5905077_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905077\n",
      "Processing float file 5904857_Sprof.nc\n",
      "5904857_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904857\n",
      "Processing float file 5905107_Sprof.nc\n",
      "5905107_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905107\n",
      "Processing float file 5905131_Sprof.nc\n",
      "5905131_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905131\n",
      "Processing float file 5905135_Sprof.nc\n",
      "5905135_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905135\n",
      "Processing float file 5905369_Sprof.nc\n",
      "5905369_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905369\n",
      "Processing float file 5905374_Sprof.nc\n",
      "5905374_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905374\n",
      "Processing float file 5905441_Sprof.nc\n",
      "5905441_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905441\n",
      "Processing float file 5905505_Sprof.nc\n",
      "Processing float file 5905638_Sprof.nc\n",
      "Processing float file 5905970_Sprof.nc\n",
      "5905638_Sprof.nc has valid BGC data\n",
      "Processing float file 5904983_Sprof.nc\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905638\n",
      "5905970_Sprof.nc has valid BGC data\n",
      "5905505_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905970\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905505\n",
      "5904983_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5904983\n",
      "Processing float file 5905075_Sprof.nc\n",
      "5905075_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905075\n",
      "Processing float file 5905980_Sprof.nc\n",
      "5905980_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905980\n",
      "Processing float file 5905983_Sprof.nc\n",
      "5905983_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905983\n",
      "Processing float file 5905992_Sprof.nc\n",
      "5905992_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905992\n",
      "Processing float file 5905996_Sprof.nc\n",
      "5905996_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905996\n",
      "Processing float file 5906026_Sprof.nc\n",
      "5906026_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906026\n",
      "Processing float file 5905372_Sprof.nc\n",
      "5905372_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905372\n",
      "Processing float file 5906042_Sprof.nc\n",
      "5906042_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906042\n",
      "Processing float file 5905079_Sprof.nc\n",
      "5905079_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905079\n",
      "Processing float file 5905376_Sprof.nc\n",
      "5905376_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905376\n",
      "Processing float file 5905981_Sprof.nc\n",
      "5905981_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905981\n",
      "Processing float file 5905076_Sprof.nc\n",
      "5905076_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905076\n",
      "Processing float file 5905109_Sprof.nc\n",
      "5905109_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905109\n",
      "Processing float file 5905972_Sprof.nc\n",
      "Processing float file 5906032_Sprof.nc\n",
      "5905972_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905972\n",
      "5906032_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906032\n",
      "Processing float file 5905531_Sprof.nc\n",
      "Processing float file 5905985_Sprof.nc\n",
      "5905531_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905531\n",
      "5905985_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905985\n",
      "Processing float file 5905442_Sprof.nc\n",
      "Processing float file 5905132_Sprof.nc\n",
      "5905442_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905442\n",
      "5905132_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905132\n",
      "Processing float file 5905139_Sprof.nc\n",
      "5905139_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905139\n",
      "Processing float file 5905993_Sprof.nc\n",
      "Processing float file 5906204_Sprof.nc\n",
      "Processing float file 5905997_Sprof.nc\n",
      "5905993_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905993\n",
      "5906204_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906204\n",
      "Processing float file 5905639_Sprof.nc\n",
      "5905997_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905997\n",
      "5905639_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905639\n",
      "Processing float file 5905368_Sprof.nc\n",
      "5905368_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905368\n",
      "Processing float file 5906043_Sprof.nc\n",
      "Processing float file 5905982_Sprof.nc\n",
      "5906043_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906043\n",
      "5905982_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905982\n",
      "Processing float file 5905637_Sprof.nc\n",
      "5905637_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905637\n",
      "Processing float file 5905373_Sprof.nc\n",
      "5905373_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905373\n",
      "Processing float file 5905994_Sprof.nc\n",
      "5905994_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905994\n",
      "Processing float file 5905973_Sprof.nc\n",
      "5905973_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905973\n",
      "Processing float file 5905377_Sprof.nc\n",
      "5905377_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905377\n",
      "Processing float file 5905134_Sprof.nc\n",
      "5905134_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905134\n",
      "Processing float file 5905101_Sprof.nc\n",
      "5905101_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905101\n",
      "Processing float file 5905501_Sprof.nc\n",
      "Processing float file 5906206_Sprof.nc\n",
      "5906206_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906206\n",
      "5905501_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905501\n",
      "Processing float file 5905988_Sprof.nc\n",
      "5905988_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905988\n",
      "Processing float file 5906039_Sprof.nc\n",
      "Processing float file 5906214_Sprof.nc\n",
      "5906214_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906214\n",
      "5906039_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906039\n",
      "Processing float file 5905130_Sprof.nc\n",
      "5905130_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905130\n",
      "Processing float file 5905969_Sprof.nc\n",
      "5905969_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5905969\n",
      "Processing float file 5906003_Sprof.nc\n",
      "5906003_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906003\n",
      "Processing float file 5906219_Sprof.nc\n",
      "5906219_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906219\n",
      "Processing float file 5906216_Sprof.nc\n",
      "5906216_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906216\n",
      "Processing float file 5906235_Sprof.nc\n",
      "Processing float file 5906244_Sprof.nc\n",
      "5906235_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906235\n",
      "5906244_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906244\n",
      "Processing float file 5906046_Sprof.nc\n",
      "5906046_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906046\n",
      "Processing float file 5906250_Sprof.nc\n",
      "5906250_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906250\n",
      "Processing float file 5906301_Sprof.nc\n",
      "5906301_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906301\n",
      "Processing float file 5906304_Sprof.nc\n",
      "5906304_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906304\n",
      "Processing float file 5906213_Sprof.nc\n",
      "5906213_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906213\n",
      "Processing float file 5906311_Sprof.nc\n",
      "5906311_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906311\n",
      "Processing float file 5906340_Sprof.nc\n",
      "5906340_Sprof.nc has valid BGC data\n",
      "Processing float file 5906436_Sprof.nc\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906340\n",
      "5906436_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906436\n",
      "Processing float file 5906439_Sprof.nc\n",
      "Processing float file 5906474_Sprof.nc\n",
      "5906439_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906439\n",
      "5906474_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906474\n",
      "Processing float file 5906507_Sprof.nc\n",
      "5906507_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906507\n",
      "Processing float file 5906513_Sprof.nc\n",
      "5906513_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906513\n",
      "Processing float file 5906520_Sprof.nc\n",
      "5906520_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906520\n",
      "Processing float file 5906571_Sprof.nc\n",
      "5906571_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906571\n",
      "Processing float file 5906217_Sprof.nc\n",
      "5906217_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906217\n",
      "Processing float file 5906237_Sprof.nc\n",
      "5906237_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906237\n",
      "Processing float file 5906515_Sprof.nc\n",
      "5906515_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906515\n",
      "Processing float file 5906489_Sprof.nc\n",
      "5906489_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906489\n",
      "Processing float file 5906437_Sprof.nc\n",
      "Processing float file 5906224_Sprof.nc\n",
      "5906437_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906437\n",
      "5906224_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906224\n",
      "Processing float file 5906307_Sprof.nc\n",
      "Processing float file 5906434_Sprof.nc\n",
      "5906307_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906307\n",
      "5906434_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906434\n",
      "Processing float file 5906468_Sprof.nc\n",
      "5906468_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906468\n",
      "Processing float file 5906316_Sprof.nc\n",
      "Processing float file 5906246_Sprof.nc\n",
      "5906316_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906316\n",
      "5906246_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906246\n",
      "Processing float file 5906302_Sprof.nc\n",
      "5906302_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906302\n",
      "Processing float file 5906522_Sprof.nc\n",
      "5906522_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906522\n",
      "Processing float file 5906293_Sprof.nc\n",
      "5906293_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906293\n",
      "Processing float file 5906636_Sprof.nc\n",
      "5906636_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906636\n",
      "Processing float file 5906510_Sprof.nc\n",
      "5906510_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906510\n",
      "Processing float file 5906623_Sprof.nc\n",
      "5906623_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906623\n",
      "Processing float file 5906518_Sprof.nc\n",
      "5906518_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906518\n",
      "Processing float file 5906238_Sprof.nc\n",
      "Processing float file 5906502_Sprof.nc\n",
      "5906238_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906238\n",
      "5906502_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906502\n",
      "Processing float file 5906536_Sprof.nc\n",
      "5906536_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906536\n",
      "Processing float file 5906471_Sprof.nc\n",
      "5906471_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906471\n",
      "Processing float file 5906438_Sprof.nc\n",
      "Processing float file 5906435_Sprof.nc\n",
      "Processing float file 5906303_Sprof.nc\n",
      "5906438_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906438\n",
      "Processing float file 5906512_Sprof.nc\n",
      "5906435_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906435\n",
      "5906303_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906303\n",
      "5906512_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906512\n",
      "Processing float file 5906310_Sprof.nc\n",
      "5906310_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906310\n",
      "Processing float file 5906318_Sprof.nc\n",
      "5906318_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906318\n",
      "Processing float file 5906247_Sprof.nc\n",
      "5906247_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906247\n",
      "Processing float file 5906227_Sprof.nc\n",
      "5906227_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906227\n",
      "Processing float file 5906296_Sprof.nc\n",
      "5906296_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906296\n",
      "Processing float file 5906765_Sprof.nc\n",
      "5906765_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906765\n",
      "Processing float file 6903551_Sprof.nc\n",
      "6903551_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 6903551\n",
      "Processing float file 5906624_Sprof.nc\n",
      "5906624_Sprof.nc has valid BGC data\n",
      "Calculating TALK, DIC and pH 25C correction for float 5906624\n",
      "Starting crossover for 1902303\n",
      "Starting crossover for 1902384\n",
      "Starting crossover for 4903026\n",
      "Starting crossover for 4903459\n",
      "Starting crossover for 1902385\n",
      "Starting crossover for 5903893\n",
      "Starting crossover for 4903462\n",
      "Starting crossover for 5904188\n",
      "Starting crossover for 5904468\n",
      "Starting crossover for 1902304\n",
      "Starting crossover for 2903451\n",
      "Starting crossover for 5904471\n",
      "Starting crossover for 5904395\n",
      "Starting crossover for 5904657\n",
      "Starting crossover for 4903486\n",
      "Starting crossover for 5904660\n",
      "Starting crossover for 5904663\n",
      "Starting crossover for 5904675\n",
      "Starting crossover for 5904658\n",
      "Starting crossover for 5904661\n",
      "Starting crossover for 5904185\n",
      "Starting crossover for 5904984\n",
      "Starting crossover for 5904682\n",
      "Starting crossover for 5904397\n",
      "Starting crossover for 1902383\n",
      "Starting crossover for 5904693\n",
      "Starting crossover for 5905077\n",
      "Starting crossover for 5904763\n",
      "Starting crossover for 5904841\n",
      "Starting crossover for 5905107\n",
      "Starting crossover for 5904695\n",
      "Starting crossover for 5904187\n",
      "Starting crossover for 5904659\n",
      "Starting crossover for 5904854\n",
      "Starting crossover for 5905131\n",
      "Starting crossover for 5905079\n",
      "Starting crossover for 5904859\n",
      "Starting crossover for 5904662\n",
      "Starting crossover for 5905075\n",
      "Starting crossover for 5904765\n",
      "Starting crossover for 5905109\n",
      "Starting crossover for 5904673\n",
      "Starting crossover for 5905135\n",
      "Starting crossover for 5904683\n",
      "Starting crossover for 5905369\n",
      "Starting crossover for 5904761\n",
      "Starting crossover for 5904856\n",
      "Starting crossover for 5905130\n",
      "Starting crossover for 5905374\n",
      "Starting crossover for 5905372\n",
      "Starting crossover for 5904678\n",
      "Starting crossover for 5905139\n",
      "Starting crossover for 5905101\n",
      "Starting crossover for 5904469\n",
      "Starting crossover for 5904685\n",
      "Starting crossover for 5905132\n",
      "Starting crossover for 5904674\n",
      "Starting crossover for 5905368\n",
      "Starting crossover for 5905373\n",
      "Starting crossover for 4903365\n",
      "Starting crossover for 5904857\n",
      "Starting crossover for 5905441\n",
      "Starting crossover for 5904766\n",
      "Starting crossover for 5904982\n",
      "Starting crossover for 5905076\n",
      "Starting crossover for 5905505\n",
      "Starting crossover for 5904472\n",
      "Starting crossover for 5905376\n",
      "Starting crossover for 5904679\n",
      "Starting crossover for 5905638\n",
      "Starting crossover for 5905970\n",
      "Starting crossover for 5905980\n",
      "Starting crossover for 5905442\n",
      "Starting crossover for 5905531\n",
      "Starting crossover for 5904983\n",
      "Starting crossover for 5905134\n",
      "Starting crossover for 5905377\n",
      "Starting crossover for 5905983\n",
      "Starting crossover for 5905981\n",
      "Starting crossover for 5904842\n",
      "Starting crossover for 5905992\n",
      "Starting crossover for 5904470\n",
      "Starting crossover for 5904474\n",
      "Starting crossover for 5905996\n",
      "Starting crossover for 5905982\n",
      "Starting crossover for 5906026\n",
      "Starting crossover for 4903456\n",
      "Starting crossover for 5904844\n",
      "Starting crossover for 5906042\n",
      "Starting crossover for 5905985\n",
      "Starting crossover for 5905997\n",
      "Starting crossover for 5906204\n",
      "Starting crossover for 5906043\n",
      "Starting crossover for 5906214\n",
      "Starting crossover for 5905993\n",
      "Starting crossover for 5905501\n",
      "Starting crossover for 5906219\n",
      "Starting crossover for 5905972\n",
      "Starting crossover for 5906206\n",
      "Starting crossover for 5906216\n",
      "Starting crossover for 5906235\n",
      "Starting crossover for 5906224\n",
      "Starting crossover for 5905973\n",
      "Starting crossover for 5906046\n",
      "Starting crossover for 5906244\n",
      "Starting crossover for 5905994\n",
      "Starting crossover for 5905637\n",
      "Starting crossover for 5906032\n",
      "Starting crossover for 5906227\n",
      "Starting crossover for 5906250\n",
      "Starting crossover for 5906213\n",
      "Starting crossover for 5906217\n",
      "Starting crossover for 5906301\n",
      "Starting crossover for 5905988\n",
      "Starting crossover for 5906293\n",
      "Starting crossover for 5906246\n",
      "Starting crossover for 5906304\n",
      "Starting crossover for 5906003\n",
      "Starting crossover for 5906311\n",
      "Starting crossover for 5906247\n",
      "Starting crossover for 5905639\n",
      "Starting crossover for 5906340\n",
      "Starting crossover for 5906436\n",
      "Starting crossover for 5906316\n",
      "Starting crossover for 5906318\n",
      "Starting crossover for 5906439\n",
      "Starting crossover for 5906039\n",
      "Starting crossover for 5906474\n",
      "Starting crossover for 5906468\n",
      "Starting crossover for 5906507\n",
      "Starting crossover for 5906489\n",
      "Starting crossover for 5906437\n",
      "Starting crossover for 5906434\n",
      "Starting crossover for 5906513\n",
      "Starting crossover for 5906237\n",
      "Starting crossover for 5906471\n",
      "Starting crossover for 5906502\n",
      "Starting crossover for 5906520\n",
      "Starting crossover for 5906238\n",
      "Starting crossover for 5906571\n",
      "Starting crossover for 5906636\n",
      "Starting crossover for 5906623\n",
      "Starting crossover for 5906510\n",
      "Starting crossover for 5906522\n",
      "Starting crossover for 5906515\n",
      "Starting crossover for 5906435\n",
      "Starting crossover for 5906296\n",
      "Starting crossover for 5906624\n",
      "Starting crossover for 5906518\n",
      "Starting crossover for 5905969\n",
      "Starting crossover for 5906765\n",
      "Starting crossover for 5906438\n",
      "Starting crossover for 6903551\n",
      "Starting crossover for 5906512\n",
      "Starting crossover for 5906536\n",
      "Starting crossover for 5906307\n",
      "Starting crossover for 5906310\n",
      "Starting crossover for 5906302\n",
      "Starting crossover for 5906303\n",
      "<xarray.Dataset>\n",
      "Dimensions:                           (N_CROSSOVERS: 48994)\n",
      "Coordinates:\n",
      "  * N_CROSSOVERS                      (N_CROSSOVERS) int64 0 1 2 3 ... 86 87 88\n",
      "Data variables: (12/44)\n",
      "    p_compare_min                     (N_CROSSOVERS) int64 1400 1400 ... 1400\n",
      "    p_compare_max                     (N_CROSSOVERS) int64 2100 2100 ... 2100\n",
      "    delta_dens                        (N_CROSSOVERS) float64 0.005 ... 0.005\n",
      "    delta_spice                       (N_CROSSOVERS) float64 0.005 ... 0.005\n",
      "    delta_press                       (N_CROSSOVERS) int64 100 100 ... 100 100\n",
      "    dist                              (N_CROSSOVERS) int64 100 100 ... 100 100\n",
      "    ...                                ...\n",
      "    glodap_longitude                  (N_CROSSOVERS) float64 1.512 ... 41.94\n",
      "    main_float_latitude               (N_CROSSOVERS) float64 -66.01 ... -48.87\n",
      "    glodap_latitude                   (N_CROSSOVERS) float64 -65.36 ... -49.5\n",
      "    glodap_cruise                     (N_CROSSOVERS) int64 2 2 6 ... 370 354 691\n",
      "    glodap_station                    (N_CROSSOVERS) float64 291.0 ... 29.0\n",
      "    glodap_obs_index                  (N_CROSSOVERS) int64 1315 2016 ... 951397\n",
      "Total number of glodap crossovers: 48994\n",
      "Program finished in 445.72430866700006 seconds - using multiprocessing\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "reload(aiac)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# 0: overwrites and runs all floats in the argo_path directory \n",
    "# 1: reads in and adds to argo_interp_temp.nc rather than overwriting and running all floats\n",
    "    # need to modify with new parallel version I think \n",
    "# 2: runs specific floats listed below\n",
    "append_data = 0\n",
    "num_processes = 18  \n",
    "\n",
    "if 'argo_interp' in locals():\n",
    "    argo_interp.close()\n",
    "    \n",
    "argolist = []\n",
    "\n",
    "for file in os.listdir(argo_path):\n",
    "    if file.endswith('Sprof.nc'):\n",
    "        argolist.append(file)\n",
    "argolist.sort()\n",
    "\n",
    "if append_data==1 and os.path.exists(data_dir+'argo_interp_temp.nc'): # no longer works in the parallel version \n",
    "    #load previously saved argo_interp\n",
    "    argo_interp = xr.load_dataset(data_dir+'argo_interp_temp.nc')\n",
    "\n",
    "    #extract wmo #s as integers from argolist\n",
    "    s = [int(s) for s in re.findall(\"[0-9]+\", str(argolist))]\n",
    "    \n",
    "    #find indices of argolist where argo_interp has no existing matching wmos\n",
    "    indices = [s.index(i) for i in s if i not in argo_interp.wmo]\n",
    "    argolist_run = [argolist[i] for i in indices]\n",
    "elif append_data==0:\n",
    "    argolist_run=argolist\n",
    "   \n",
    "else:\n",
    "    # argolist_run = ['5906547_Sprof.nc']\n",
    "    argolist_run = ['5904674_Sprof.nc',\n",
    "                    '5905135_Sprof.nc',\n",
    "                    '5906204_Sprof.nc',\n",
    "                    '5906489_Sprof.nc']\n",
    "    # argolist_run = ['5906547_Sprof.nc',\n",
    "    #                     '5906548_Sprof.nc',\n",
    "    #                     '5906549_Sprof.nc', \n",
    "    #                     '5906550_Sprof.nc', \n",
    "    #                     '5906551_Sprof.nc', \n",
    "    #                     '5906552_Sprof.nc', \n",
    "    #                     '5906553_Sprof.nc',\n",
    "    #                     '5906562_Sprof.nc',\n",
    "    #                     '5906554_Sprof.nc',\n",
    "    #                     '5906561_Sprof.nc', \n",
    "    #                     '5906556_Sprof.nc',\n",
    "    #                     '5906558_Sprof.nc',\n",
    "    #                     '5906559_Sprof.nc',\n",
    "    #                     '5906557_Sprof.nc']\n",
    "\n",
    "#restrict glodap data to comparison pressure range\n",
    "gdap_p = gdap[(gdap.PRES_ADJUSTED.values>p_compare_min) & (gdap.PRES_ADJUSTED.values<p_compare_max)]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        # Create a list of arguments for pool.starmap\n",
    "        argo_args = [(argo_path, liar_dir, argo_path_interpolated, argo_path_derived, file, qc_data_fields, bgc_data_fields, p_interp, derived_list, interpolation_list, adjustment) for file in argolist_run]\n",
    "        \n",
    "        # Use pool.starmap with the list of arguments\n",
    "        pool.starmap(aiac.argo_interp_profiles, argo_args)\n",
    "    \n",
    "    \n",
    "    # only run glodap crossovers on floats that have an interpolated file \n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        # Create a list of arguments for pool.starmap\n",
    "        argo_args = [(argo_path_interpolated, offset_dir, glodap_file_offsets_dir, file, dist, delta_dens, delta_spice, delta_press, \\\n",
    "                        gdap_p, p_interp, plot_profile, var_list_plot, p_compare_min, p_compare_max) for file in argolist_run]\n",
    "        \n",
    "        # Use pool.starmap with the list of arguments\n",
    "        pool.starmap(aiac.glodap_crossover_offsets, argo_args)\n",
    "\n",
    "# Now load in all individual offset files and concatenate into larger file\n",
    "crossover_list = []\n",
    "for file in os.listdir(glodap_file_offsets_dir):\n",
    "    if file.endswith('_offset.nc'):\n",
    "        crossover_list.append(file)\n",
    "# print(len(crossover_list))\n",
    "\n",
    "if 'glodap_offsets' in locals():\n",
    "       del glodap_offsets # deletes argo_interp in case this code is being run multiple times. \n",
    "\n",
    "for idx, gdap_offset_file in enumerate(crossover_list):\n",
    "    # print(idx)\n",
    "    # print(gdap_offset_file)\n",
    "    gdap_offset_n = xr.open_dataset(glodap_file_offsets_dir + gdap_offset_file)\n",
    "\n",
    "    if len(gdap_offset_n['N_CROSSOVERS'])>0:\n",
    "        if 'glodap_offsets' not in locals(): # modified to deal w/ situation where n==0 skipped defining argo_interp\n",
    "            glodap_offsets = gdap_offset_n\n",
    "        else:\n",
    "            glodap_offsets = xr.concat([glodap_offsets,gdap_offset_n],'N_CROSSOVERS')\n",
    "print(glodap_offsets)\n",
    "\n",
    "glodap_offsets.to_netcdf(output_dir+glodap_offsets_filename)\n",
    "\n",
    "print('Total number of glodap crossovers: ' + str(len(glodap_offsets.N_CROSSOVERS)))\n",
    "\n",
    "finish_time = time.perf_counter()\n",
    "print(\"Program finished in {} seconds - using multiprocessing\".format(finish_time - start_time))\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting crossover for 7901028_glodap_\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/Users/smb-uh/UHM_Ocean_BGC_Group Dropbox/Datasets/Data_Products/BGC_ARGO_GLOBAL/2023_06_20/interpolated_for_crossovers_100km_1400_to_2100_100m_0.005dens_0.005_spice_7/7901028_glodap__interpolated.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/xarray/backends/file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_key]\n\u001b[1;32m    200\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/xarray/backends/lru_cache.py:53\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m---> 53\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache[key]\n\u001b[1;32m     54\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/Users/smb-uh/UHM_Ocean_BGC_Group Dropbox/Datasets/Data_Products/BGC_ARGO_GLOBAL/2023_06_20/interpolated_for_crossovers_100km_1400_to_2100_100m_0.005dens_0.005_spice_7/7901028_glodap__interpolated.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/smb-uh/UHM_Ocean_BGC_Group Dropbox/Seth Bushinsky/Work/Manuscripts/2022_07 Deep O2 Bias/argo_deep_o2_bias/float_bgc_bias_correction_parallel.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/smb-uh/UHM_Ocean_BGC_Group%20Dropbox/Seth%20Bushinsky/Work/Manuscripts/2022_07%20Deep%20O2%20Bias/argo_deep_o2_bias/float_bgc_bias_correction_parallel.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m aiac\u001b[39m.\u001b[39;49mglodap_crossover_offsets(argo_path_interpolated, offset_dir, glodap_file_offsets_dir, argolist_run[\u001b[39m0\u001b[39;49m], dist, delta_dens, delta_spice, delta_press, \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/smb-uh/UHM_Ocean_BGC_Group%20Dropbox/Seth%20Bushinsky/Work/Manuscripts/2022_07%20Deep%20O2%20Bias/argo_deep_o2_bias/float_bgc_bias_correction_parallel.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                         gdap_p, p_interp, plot_profile, var_list_plot, p_compare_min, p_compare_max)\n",
      "File \u001b[0;32m~/UHM_Ocean_BGC_Group Dropbox/Seth Bushinsky/Work/Manuscripts/2022_07 Deep O2 Bias/argo_deep_o2_bias/argo_interp_and_crossover.py:297\u001b[0m, in \u001b[0;36mglodap_crossover_offsets\u001b[0;34m(argo_path_interpolated, offset_dir, glodap_file_offsets_dir, argo_file, dist, delta_dens, delta_spice, delta_press, gdap_p, p_interp, plot_profile, var_list_plot, p_compare_min, p_compare_max)\u001b[0m\n\u001b[1;32m    294\u001b[0m wmo \u001b[39m=\u001b[39m argo_file[\u001b[39m0\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m17\u001b[39m]\n\u001b[1;32m    295\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStarting crossover for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m wmo)\n\u001b[0;32m--> 297\u001b[0m argo_interp_n \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mopen_dataset(argo_path_interpolated \u001b[39m+\u001b[39m wmo \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_interpolated.nc\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    298\u001b[0m \u001b[39mprint\u001b[39m(argo_interp_n\u001b[39m.\u001b[39mN_CROSSOVERS)\n\u001b[1;32m    299\u001b[0m \u001b[39m#number of profiles\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/xarray/backends/api.py:495\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, backend_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m decoders \u001b[39m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    484\u001b[0m     decode_cf,\n\u001b[1;32m    485\u001b[0m     open_backend_dataset_parameters\u001b[39m=\u001b[39mbackend\u001b[39m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    491\u001b[0m     decode_coords\u001b[39m=\u001b[39mdecode_coords,\n\u001b[1;32m    492\u001b[0m )\n\u001b[1;32m    494\u001b[0m overwrite_encoded_chunks \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39moverwrite_encoded_chunks\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 495\u001b[0m backend_ds \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mopen_dataset(\n\u001b[1;32m    496\u001b[0m     filename_or_obj,\n\u001b[1;32m    497\u001b[0m     drop_variables\u001b[39m=\u001b[39;49mdrop_variables,\n\u001b[1;32m    498\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdecoders,\n\u001b[1;32m    499\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    500\u001b[0m )\n\u001b[1;32m    501\u001b[0m ds \u001b[39m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    502\u001b[0m     backend_ds,\n\u001b[1;32m    503\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    511\u001b[0m )\n\u001b[1;32m    512\u001b[0m \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:553\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen_dataset\u001b[39m(\n\u001b[1;32m    533\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    534\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    549\u001b[0m     autoclose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    550\u001b[0m ):\n\u001b[1;32m    552\u001b[0m     filename_or_obj \u001b[39m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 553\u001b[0m     store \u001b[39m=\u001b[39m NetCDF4DataStore\u001b[39m.\u001b[39;49mopen(\n\u001b[1;32m    554\u001b[0m         filename_or_obj,\n\u001b[1;32m    555\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    556\u001b[0m         \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    557\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    558\u001b[0m         clobber\u001b[39m=\u001b[39;49mclobber,\n\u001b[1;32m    559\u001b[0m         diskless\u001b[39m=\u001b[39;49mdiskless,\n\u001b[1;32m    560\u001b[0m         persist\u001b[39m=\u001b[39;49mpersist,\n\u001b[1;32m    561\u001b[0m         lock\u001b[39m=\u001b[39;49mlock,\n\u001b[1;32m    562\u001b[0m         autoclose\u001b[39m=\u001b[39;49mautoclose,\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    565\u001b[0m     store_entrypoint \u001b[39m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    566\u001b[0m     \u001b[39mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:382\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    376\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    377\u001b[0m     clobber\u001b[39m=\u001b[39mclobber, diskless\u001b[39m=\u001b[39mdiskless, persist\u001b[39m=\u001b[39mpersist, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m\n\u001b[1;32m    378\u001b[0m )\n\u001b[1;32m    379\u001b[0m manager \u001b[39m=\u001b[39m CachingFileManager(\n\u001b[1;32m    380\u001b[0m     netCDF4\u001b[39m.\u001b[39mDataset, filename, mode\u001b[39m=\u001b[39mmode, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    381\u001b[0m )\n\u001b[0;32m--> 382\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(manager, group\u001b[39m=\u001b[39;49mgroup, mode\u001b[39m=\u001b[39;49mmode, lock\u001b[39m=\u001b[39;49mlock, autoclose\u001b[39m=\u001b[39;49mautoclose)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:330\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group \u001b[39m=\u001b[39m group\n\u001b[1;32m    329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m mode\n\u001b[0;32m--> 330\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mds\u001b[39m.\u001b[39mdata_model\n\u001b[1;32m    331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mds\u001b[39m.\u001b[39mfilepath()\n\u001b[1;32m    332\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_remote \u001b[39m=\u001b[39m is_remote_uri(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:391\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mds\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_acquire()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:385\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_acquire\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 385\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manager\u001b[39m.\u001b[39macquire_context(needs_lock) \u001b[39mas\u001b[39;00m root:\n\u001b[1;32m    386\u001b[0m         ds \u001b[39m=\u001b[39m _nc4_require_group(root, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode)\n\u001b[1;32m    387\u001b[0m     \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/xarray/backends/file_manager.py:187\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39m@contextlib\u001b[39m\u001b[39m.\u001b[39mcontextmanager\n\u001b[1;32m    185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39macquire_context\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    186\u001b[0m     \u001b[39m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m     file, cached \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_acquire_with_cache_info(needs_lock)\n\u001b[1;32m    188\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m         \u001b[39myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/float_bgc_synthesis_products/lib/python3.9/site-packages/xarray/backends/file_manager.py:205\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    203\u001b[0m     kwargs \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    204\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode\n\u001b[0;32m--> 205\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_opener(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    207\u001b[0m     \u001b[39m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2463\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2026\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/Users/smb-uh/UHM_Ocean_BGC_Group Dropbox/Datasets/Data_Products/BGC_ARGO_GLOBAL/2023_06_20/interpolated_for_crossovers_100km_1400_to_2100_100m_0.005dens_0.005_spice_7/7901028_glodap__interpolated.nc'"
     ]
    }
   ],
   "source": [
    "aiac.glodap_crossover_offsets(argo_path_interpolated, offset_dir, glodap_file_offsets_dir, argolist_run[0], dist, delta_dens, delta_spice, delta_press, \\\n",
    "                        gdap_p, p_interp, plot_profile, var_list_plot, p_compare_min, p_compare_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591\n"
     ]
    }
   ],
   "source": [
    "# Now load in all individual offset files and concatenate into larger file\n",
    "interpolated_list = []\n",
    "for file in os.listdir(argo_path_interpolated):\n",
    "    if file.endswith('_interpolated.nc'):\n",
    "        interpolated_list.append(file)\n",
    "print(len(interpolated_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "argo_args = [(argo_path_interpolated, offset_dir, glodap_file_offsets_dir, file, dist, delta_dens, delta_spice, delta_press, \\\n",
    "                        gdap_p, p_interp, plot_profile, var_list_plot, p_compare_min, p_compare_max) for file in interpolated_list]\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
